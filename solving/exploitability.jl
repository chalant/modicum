module exploitability

using bestresponse
using infosets

@inline function updatereachprobs!(arr::V, pl::I, p::T) where {N, I<:Integer, T<:AbstractFloat, V<:StaticVector{N, T}}
    return StaticArrays.sacollect(SVector{N, T}, playerreachprob!(arr, pl, i, p) for i in 1:N)
end

function expectedvalue!(
    gs::G, h::H, br_h::B, pl::I, 
    chance_action::C, state::I, 
    reach_probs::R) where {
    A, P, T<:AbstractFloat, R<:StaticVector{3, T}, 
    C<:ChanceAction, I<:Integer, G<:AbstractGameState, 
    H<:AbstractHistory{A, G}, K<:Real, U<:StaticVector{A, K}, V<:StaticVector{P, U}, 
    K1<:Integer, K2<:Integer, B<:BRHistory{V, K1, K2}}

    # note: calculating exploitability should be used for research or debugging purposes...
    # because it takes up too much memory since it traverses all the game tree!

    key = infosetkey(gs)
    info = infoset(h, key)

    a_mask = actionsmask!(gs)
    n_actions = sum(a_mask)
    lga = legalactions!(a_mask, n_actions)

    actions = actions!(gs)

    if terminal!(gs, state) == true
        return computeutility!(gs, pl)
    end

    if chance!(gs, state) == true
        ev = T(0)

        #todo: parallelize this...

        for a in chanceactions!(gs, chance_action)
            ha = history(h, a.idx)

            p = chanceprobability!(T, gs, chance_action)

            game_state = ha.game_state
            copy!(game_state, gs)

            state = performchance!(a, game_state, game_state.player)

            ev += solve(
                solver, 
                game_state, 
                ha, a, pl, 
                state,
                @SVector [reach_probs[1], reach_probs[2], reach_probs[3] * p]) * p
        end

        return ev

    end

    a_mask = actionsmask!(gs)
    n_actions = sum(a_mask)
    lga = legalactions!(a_mask, n_actions)

    actions = actions!(gs)

    if player == gs.player

        cum_stg = cumulativestrategy!(info, pl)
        stg = SVector{A, T}(cum_stg) ./ sum(cum_stg)

        util = T(0)

        for i in 1:n_actions
            idx = lga[i]
            
            ha = history(h, idx)

            copy!(ha.game_state, gs)

            perform!(actions[idx], gs, gs.player)

            util += expectedvalue!(
                gs, ha, br_h, 
                pl, 
                chance_action, 
                state, 
                updatereachprobs!(reach_probs, pl, stg[idx])) * stg[idx]
        end

        return util
    end

    stg = getstrategy!(br_h, key, pl)

    #only perform once for best response strategy
    i = argmax(stg)

    idx = lga[i]
            
    ha = history(h, idx)

    copy!(ha.game_state, gs)

    perform!(actions[i], gs, gs.player)

    return stg[i] * expectedvalue!(
        gs, ha, 
        br_h, pl, 
        chance_action, 
        state, 
        reach_probs)
end

function expectedvalue!(
    gs::G, h::H, br_h::B, pl::I, 
    chance_action::C, state::I, 
    reach_probs::R) where {
    A, P, T<:AbstractFloat, R<:StaticVector{3, T}, 
    C<:ChanceAction, I<:Integer, G<:AbstractGameState, 
    H<:AbstractHistory{A, G}, U<:Integer, V<:StaticVector{P, U}, 
    K1<:Integer, K2<:Integer, B<:BRHistory{V, K1, K2}}
    
    # note: calculating exploitability should be used for research or debugging purposes...
    # because it takes up too much memory since it traverses all the game tree!

    key = infosetkey(gs)
    info = infoset(h, key)

    cum_stg = cumulativestrategy!(info, pl)
    stg = SVector{A, T}(cum_stg) ./ sum(cum_stg)

    a_mask = actionsmask!(gs)
    n_actions = sum(a_mask)
    lga = legalactions!(a_mask, n_actions)

    actions = actions!(gs)

    if terminal!(gs, state) == true
        return computeutility!(gs, pl)
    end

    if chance!(gs, state) == true
        ev = T(0)

        #todo: parallelize this...

        for a in chanceactions!(gs, chance_action)
            ha = history(h, a.idx)

            p = chanceprobability!(gs, chance_action)

            game_state = ha.game_state
            copy!(game_state, gs)

            state = performchance!(a, game_state, game_state.player)

            ev += solve(
                solver, 
                game_state, 
                ha, a, pl, 
                state,
                @SVector [reach_probs[1], reach_probs[2], reach_probs[3] * p]) * p
        end

        return ev

    end

    a_mask = actionsmask!(gs)
    n_actions = sum(a_mask)
    lga = legalactions!(a_mask, n_actions)

    actions = actions!(gs)

    if player == gs.player
        util = T(0)

        for i in 1:n_actions
            idx = lga[i]
            
            ha = history(h, idx)

            copy!(ha.game_state, gs)

            perform!(actions[idx], gs, gs.player)

            util += expectedvalue!(
                gs, ha, br_h, 
                pl, 
                chance_action, 
                state, 
                updatereachprobs!(reach_probs, pl, stg[idx])) * stg[idx]
        end

        return util
    end

    #only perform once for best response strategy
    stg_idx = getstrategy!(br_h, key, pl)

    idx = lga[i]
            
    ha = history(h, idx)

    copy!(ha.game_state, gs)

    perform!(actions[stg_idx], gs, gs.player)

    return stg[stg_idx] * expectedvalue!(
        gs, ha, 
        br_h, pl, 
        chance_action, 
        state, 
        reach_probs)

end

function computeexploitability!(gs::G, h::H, br_h::B) where {A, S<:GameSetup, G<:AbstractGameState{A, S, 2}, H<:AbstractHistory, B<:BestResponseHistory}
    ica = initialchanceaction(gs)
    ist = initialstate(gs)
    init_reach = @SVector [1, 1, 1]

    # create/update best response strategies for each player
    for pl in players!(gs)
        bestresponse!(
            gs, h, br_h, 
            ica, pl, ist, 
            init_reach)
    end

    ev = T(0)

    # compute expected value for playing against a strategy for
    # each player
    for pl in players!(gs)
        ev += expectedvalue!(
            gs, h, 
            br_h, pl, 
            ica, 
            ist,
            init_reach)
    end

    return ev / 2 * 1000

end

end